% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/textcleaning.R
\name{vocab_tokens}
\alias{vocab_tokens}
\title{Create Vocab for Tokens}
\usage{
vocab_tokens(tokens)
}
\arguments{
\item{tokens}{a list of tokenized entries}
}
\value{
a character vector containing each unique token entry that appears in tokenized document.
}
\description{
collect all unique tokens in the full set of tokens.
Returns a character vector of the unique tokens across all entries.
}
\examples{
vocab_tokens( list( c( 'first', 'entr', 'doc' ), c('second', 'entr', 'doc') ) )
}
