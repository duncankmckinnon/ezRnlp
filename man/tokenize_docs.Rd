% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/textcleaning.R
\name{tokenize_docs}
\alias{tokenize_docs}
\title{Tokenize Docs}
\usage{
tokenize_docs(docs)
}
\arguments{
\item{docs}{a vector or list of text samples}
}
\value{
a list of tokenized results for each each entry in the doc
}
\description{
performs vectorized tokenization for each entry of the document
}
\examples{
tokenize_docs( c('First entry of the doc,', 'Second entry of the doc.') )
}
